{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc2d773",
   "metadata": {},
   "source": [
    "# Name: Travel Planning\n",
    "\n",
    "## Description: Group Chat for Planning a Travel\n",
    "\n",
    "## Tags: Planning, Group, Travel\n",
    "\n",
    "###ðŸ§© generated with â¤ï¸ by Waldiez.\n",
    "\n",
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c62605",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys  # pyright: ignore\n",
    "\n",
    "# # !{sys.executable} -m pip install -q ag2[openai]==0.9.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9908ac",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa5d3b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# pyright: reportUnusedImport=false,reportMissingTypeStubs=false\n",
    "import asyncio\n",
    "import csv\n",
    "import importlib\n",
    "import json\n",
    "import os\n",
    "import sqlite3\n",
    "import sys\n",
    "import traceback\n",
    "from dataclasses import asdict\n",
    "from pprint import pprint\n",
    "from types import ModuleType\n",
    "from typing import (\n",
    "    Annotated,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Coroutine,\n",
    "    Dict,\n",
    "    List,\n",
    "    Optional,\n",
    "    Set,\n",
    "    Tuple,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "import autogen  # type: ignore\n",
    "from autogen import (\n",
    "    Agent,\n",
    "    Cache,\n",
    "    ChatResult,\n",
    "    ConversableAgent,\n",
    "    GroupChat,\n",
    "    UserProxyAgent,\n",
    "    runtime_logging,\n",
    ")\n",
    "from autogen.agentchat import GroupChatManager, run_group_chat\n",
    "from autogen.agentchat.group import ContextVariables\n",
    "from autogen.agentchat.group.patterns import RoundRobinPattern\n",
    "from autogen.events import BaseEvent\n",
    "from autogen.io.run_response import AsyncRunResponseProtocol, RunResponseProtocol\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Common environment variable setup for Waldiez flows\n",
    "load_dotenv(override=True)\n",
    "os.environ[\"AUTOGEN_USE_DOCKER\"] = \"0\"\n",
    "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"False\"\n",
    "#\n",
    "# let's try to avoid:\n",
    "# module 'numpy' has no attribute '_no_nep50_warning'\"\n",
    "# ref: https://github.com/numpy/numpy/blob/v2.2.2/doc/source/release/2.2.0-notes.rst#nep-50-promotion-state-option-removed\n",
    "os.environ[\"NEP50_DEPRECATION_WARNING\"] = \"0\"\n",
    "os.environ[\"NEP50_DISABLE_WARNING\"] = \"1\"\n",
    "os.environ[\"NPY_PROMOTION_STATE\"] = \"weak\"\n",
    "if not hasattr(np, \"_no_pep50_warning\"):\n",
    "\n",
    "    import contextlib\n",
    "    from typing import Generator\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def _np_no_nep50_warning() -> Generator[None, None, None]:\n",
    "        \"\"\"Dummy function to avoid the warning.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        None\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "        yield\n",
    "\n",
    "    setattr(np, \"_no_pep50_warning\", _np_no_nep50_warning)  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e3574",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e66944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_logging() -> None:\n",
    "    \"\"\"Start logging.\"\"\"\n",
    "    runtime_logging.start(\n",
    "        logger_type=\"sqlite\",\n",
    "        config={\"dbname\": \"flow.db\"},\n",
    "    )\n",
    "\n",
    "\n",
    "start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c59e830",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Load model API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960dae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# This section assumes that a file named:\n",
    "# \"travel_planning_api_keys.py\"\n",
    "# exists in the same directory as this file.\n",
    "# This file contains the API keys for the models used in this flow.\n",
    "# It should be .gitignored and not shared publicly.\n",
    "# If this file is not present, you can either create it manually\n",
    "# or change the way API keys are loaded in the flow.\n",
    "\n",
    "\n",
    "def load_api_key_module(flow_name: str) -> ModuleType:\n",
    "    \"\"\"Load the api key module.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flow_name : str\n",
    "        The flow name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ModuleType\n",
    "        The api keys loading module.\n",
    "    \"\"\"\n",
    "    module_name = f\"{flow_name}_api_keys\"\n",
    "    if module_name in sys.modules:\n",
    "        return importlib.reload(sys.modules[module_name])\n",
    "    return importlib.import_module(module_name)\n",
    "\n",
    "\n",
    "__MODELS_MODULE__ = load_api_key_module(\"travel_planning\")\n",
    "\n",
    "\n",
    "def get_travel_planning_model_api_key(model_name: str) -> str:\n",
    "    \"\"\"Get the model api key.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        The model name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The model api key.\n",
    "    \"\"\"\n",
    "    return __MODELS_MODULE__.get_travel_planning_model_api_key(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2d2c20",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80355a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_turbo_llm_config: dict[str, Any] = {\n",
    "    \"model\": \"gpt-4-turbo\",\n",
    "    \"api_type\": \"openai\",\n",
    "    \"api_key\": get_travel_planning_model_api_key(\"gpt_4_turbo\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e66f6fd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aac17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportUnnecessaryIsInstance=false\n",
    "\n",
    "language_agent = ConversableAgent(\n",
    "    name=\"language_agent\",\n",
    "    description=\"A helpful assistant that can provide language tips for a given destination.\",\n",
    "    system_message=\"You are a helpful assistant that can review travel plans, providing feedback on important/critical tips about how best to address language or communication challenges for the given destination. If the plan already includes language tips, you can mention that the plan is satisfactory, with rationale. \",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=lambda x: any(\n",
    "        isinstance(x, dict)\n",
    "        and x.get(\"content\", \"\")\n",
    "        and isinstance(x.get(\"content\", \"\"), str)\n",
    "        and x.get(\"content\", \"\").endswith(keyword)\n",
    "        for keyword in [\"TERMINATION\"]\n",
    "    ),\n",
    "    functions=[],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "local_agent = ConversableAgent(\n",
    "    name=\"local_agent\",\n",
    "    description=\"A local assistant that can suggest local activities or places to visit.\",\n",
    "    system_message=\"You are a helpful assistant that can suggest authentic and interesting local activities or places to visit for a user and can utilize any context information provided.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=lambda x: any(\n",
    "        isinstance(x, dict)\n",
    "        and x.get(\"content\", \"\")\n",
    "        and isinstance(x.get(\"content\", \"\"), str)\n",
    "        and x.get(\"content\", \"\").endswith(keyword)\n",
    "        for keyword in [\"TERMINATION\"]\n",
    "    ),\n",
    "    functions=[],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "planner_agent = ConversableAgent(\n",
    "    name=\"planner_agent\",\n",
    "    description=\"A helpful assistant that can plan trips.\",\n",
    "    system_message=\"You are a helpful assistant that can suggest a travel plan for a user based on their request.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=lambda x: any(\n",
    "        isinstance(x, dict)\n",
    "        and x.get(\"content\", \"\")\n",
    "        and isinstance(x.get(\"content\", \"\"), str)\n",
    "        and x.get(\"content\", \"\").endswith(keyword)\n",
    "        for keyword in [\"TERMINATION\"]\n",
    "    ),\n",
    "    functions=[],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "travel_summary_agent = ConversableAgent(\n",
    "    name=\"travel_summary_agent\",\n",
    "    description=\"A helpful assistant that aggregates suggestions and generates a final detailed travel plan.\",\n",
    "    system_message=\"You are a helpful assistant that can take in all of the suggestions and advice from the other agents and provide a detailed final travel plan. You must ensure th b at the final plan is integrated and complete. YOUR FINAL RESPONSE MUST BE THE COMPLETE PLAN. When the plan is complete and all perspectives are integrated, you can respond with TERMINATE.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=lambda x: any(\n",
    "        isinstance(x, dict)\n",
    "        and x.get(\"content\", \"\")\n",
    "        and isinstance(x.get(\"content\", \"\"), str)\n",
    "        and x.get(\"content\", \"\").endswith(keyword)\n",
    "        for keyword in [\"TERMINATION\"]\n",
    "    ),\n",
    "    functions=[],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    description=\"A new User proxy agent\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=lambda x: any(\n",
    "        isinstance(x, dict)\n",
    "        and x.get(\"content\", \"\")\n",
    "        and isinstance(x.get(\"content\", \"\"), str)\n",
    "        and x.get(\"content\", \"\").endswith(keyword)\n",
    "        for keyword in [\"TERMINATION\"]\n",
    "    ),\n",
    "    llm_config=False,  # pyright: ignore\n",
    ")\n",
    "\n",
    "manager_pattern = RoundRobinPattern(\n",
    "    initial_agent=planner_agent,\n",
    "    agents=[planner_agent, local_agent, language_agent, travel_summary_agent],\n",
    "    user_agent=user_proxy,\n",
    "    group_manager_args={\n",
    "        \"llm_config\": autogen.LLMConfig(\n",
    "            config_list=[\n",
    "                gpt_4_turbo_llm_config,\n",
    "            ],\n",
    "            cache_seed=None,\n",
    "        ),\n",
    "        \"name\": \"manager\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "def get_sqlite_out(dbname: str, table: str, csv_file: str) -> None:\n",
    "    \"\"\"Convert a sqlite table to csv and json files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dbname : str\n",
    "        The sqlite database name.\n",
    "    table : str\n",
    "        The table name.\n",
    "    csv_file : str\n",
    "        The csv file name.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(dbname)\n",
    "    query = f\"SELECT * FROM {table}\"  # nosec\n",
    "    try:\n",
    "        cursor = conn.execute(query)\n",
    "    except sqlite3.OperationalError:\n",
    "        conn.close()\n",
    "        return\n",
    "    rows = cursor.fetchall()\n",
    "    column_names = [description[0] for description in cursor.description]\n",
    "    data = [dict(zip(column_names, row, strict=True)) for row in rows]\n",
    "    conn.close()\n",
    "    with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        csv_writer = csv.DictWriter(file, fieldnames=column_names)\n",
    "        csv_writer.writeheader()\n",
    "        csv_writer.writerows(data)\n",
    "    json_file = csv_file.replace(\".csv\", \".json\")\n",
    "    with open(json_file, \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "        json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def stop_logging() -> None:\n",
    "    \"\"\"Stop logging.\"\"\"\n",
    "    runtime_logging.stop()\n",
    "    if not os.path.exists(\"logs\"):\n",
    "        os.makedirs(\"logs\")\n",
    "    for table in [\n",
    "        \"chat_completions\",\n",
    "        \"agents\",\n",
    "        \"oai_wrappers\",\n",
    "        \"oai_clients\",\n",
    "        \"version\",\n",
    "        \"events\",\n",
    "        \"function_calls\",\n",
    "    ]:\n",
    "        dest = os.path.join(\"logs\", f\"{table}.csv\")\n",
    "        get_sqlite_out(\"flow.db\", table, dest)\n",
    "\n",
    "\n",
    "def _check_for_extra_agents(agent: ConversableAgent) -> list[ConversableAgent]:\n",
    "    _extra_agents: list[ConversableAgent] = []\n",
    "    _agent_cls_name = agent.__class__.__name__\n",
    "    if _agent_cls_name == \"CaptainAgent\":\n",
    "        _assistant_agent = getattr(agent, \"assistant\", None)\n",
    "        if _assistant_agent and _assistant_agent not in _extra_agents:\n",
    "            _extra_agents.append(_assistant_agent)\n",
    "        _executor_agent = getattr(agent, \"executor\", None)\n",
    "        if _executor_agent and _executor_agent not in _extra_agents:\n",
    "            _extra_agents.append(_executor_agent)\n",
    "    return _extra_agents\n",
    "\n",
    "\n",
    "def _check_for_group_members(agent: ConversableAgent) -> list[ConversableAgent]:\n",
    "    _extra_agents: list[ConversableAgent] = []\n",
    "    _group_chat = getattr(agent, \"_groupchat\", None)\n",
    "    if _group_chat:\n",
    "        _chat_agents = getattr(_group_chat, \"agents\", [])\n",
    "        if isinstance(_chat_agents, list):\n",
    "            for _group_member in _chat_agents:\n",
    "                if _group_member not in _extra_agents:\n",
    "                    _extra_agents.append(_group_member)\n",
    "    _manager = getattr(agent, \"_group_manager\", None)\n",
    "    if _manager:\n",
    "        if _manager not in _extra_agents:\n",
    "            _extra_agents.append(_manager)\n",
    "        for _group_member in _check_for_group_members(_manager):\n",
    "            if _group_member not in _extra_agents:\n",
    "                _extra_agents.append(_group_member)\n",
    "    return _extra_agents\n",
    "\n",
    "\n",
    "def _get_known_agents() -> list[ConversableAgent]:\n",
    "    _known_agents: list[ConversableAgent] = []\n",
    "    if user_proxy not in _known_agents:\n",
    "        _known_agents.append(user_proxy)\n",
    "    _known_agents.append(user_proxy)\n",
    "    for _group_member in _check_for_group_members(user_proxy):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(user_proxy):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if planner_agent not in _known_agents:\n",
    "        _known_agents.append(planner_agent)\n",
    "    _known_agents.append(planner_agent)\n",
    "    for _group_member in _check_for_group_members(planner_agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(planner_agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if local_agent not in _known_agents:\n",
    "        _known_agents.append(local_agent)\n",
    "    _known_agents.append(local_agent)\n",
    "    for _group_member in _check_for_group_members(local_agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(local_agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if language_agent not in _known_agents:\n",
    "        _known_agents.append(language_agent)\n",
    "    _known_agents.append(language_agent)\n",
    "    for _group_member in _check_for_group_members(language_agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(language_agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if travel_summary_agent not in _known_agents:\n",
    "        _known_agents.append(travel_summary_agent)\n",
    "    _known_agents.append(travel_summary_agent)\n",
    "    for _group_member in _check_for_group_members(travel_summary_agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(travel_summary_agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "    return _known_agents\n",
    "\n",
    "\n",
    "def store_error(exc: BaseException | None = None) -> None:\n",
    "    \"\"\"Store the error in error.json.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exc : BaseException | None\n",
    "        The exception we got if any.\n",
    "    \"\"\"\n",
    "    reason = \"Event handler stopped processing\" if not exc else traceback.format_exc()\n",
    "    try:\n",
    "        with open(\"error.json\", \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "            file.write(json.dumps({\"error\": reason}))\n",
    "    except BaseException:  # pylint: disable=broad-exception-caught\n",
    "        pass\n",
    "\n",
    "\n",
    "def store_results(result_dicts: list[dict[str, Any]]) -> None:\n",
    "    \"\"\"Store the results to results.json.\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_dicts : list[dict[str, Any]]\n",
    "        The list of the results.\n",
    "    \"\"\"\n",
    "    with open(\"results.json\", \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "        file.write(json.dumps({\"results\": result_dicts}, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b7d93",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb9eea",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main(\n",
    "    on_event: Optional[\n",
    "        Callable[[BaseEvent, Optional[list[ConversableAgent]]], bool]\n",
    "    ] = None,\n",
    ") -> list[dict[str, Any]]:\n",
    "    \"\"\"Start chatting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict[str, Any]]\n",
    "        The result of the chat session.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    SystemExit\n",
    "        If the user interrupts the chat session.\n",
    "    \"\"\"\n",
    "    results: list[RunResponseProtocol] | RunResponseProtocol = []\n",
    "    result_dicts: list[dict[str, Any]] = []\n",
    "    with Cache.disk(cache_seed=42) as cache:  # pyright: ignore\n",
    "        results = run_group_chat(\n",
    "            pattern=manager_pattern,\n",
    "            messages=\"Plan a 3 day trip to Athens.\",\n",
    "            max_rounds=12,\n",
    "        )\n",
    "        if not isinstance(results, list):\n",
    "            results = [results]  # pylint: disable=redefined-variable-type\n",
    "        got_agents = False\n",
    "        known_agents: list[ConversableAgent] = []\n",
    "        if on_event:\n",
    "            for index, result in enumerate(results):\n",
    "                result_events: list[dict[str, Any]] = []\n",
    "                for event in result.events:\n",
    "                    try:\n",
    "                        result_events.append(\n",
    "                            event.model_dump(mode=\"json\", fallback=str)\n",
    "                        )\n",
    "                    except BaseException:  # pylint: disable=broad-exception-caught\n",
    "                        pass\n",
    "                    if not got_agents:\n",
    "                        known_agents = _get_known_agents()\n",
    "                        got_agents = True\n",
    "                    try:\n",
    "                        should_continue = on_event(event, known_agents)\n",
    "                    except BaseException as e:\n",
    "                        stop_logging()\n",
    "                        store_error(e)\n",
    "                        raise SystemExit(\"Error in event handler: \" + str(e)) from e\n",
    "                    if event.type == \"run_completion\":\n",
    "                        break\n",
    "                    if not should_continue:\n",
    "                        stop_logging()\n",
    "                        store_error()\n",
    "                        raise SystemExit(\"Event handler stopped processing\")\n",
    "                result_dict = {\n",
    "                    \"index\": index,\n",
    "                    \"uuid\": str(result.uuid),\n",
    "                    \"events\": result_events,\n",
    "                    \"messages\": result.messages,\n",
    "                    \"summary\": result.summary,\n",
    "                    \"cost\": (\n",
    "                        result.cost.model_dump(mode=\"json\", fallback=str)\n",
    "                        if result.cost\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"context_variables\": (\n",
    "                        result.context_variables.model_dump(mode=\"json\", fallback=str)\n",
    "                        if result.context_variables\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"last_speaker\": result.last_speaker,\n",
    "                }\n",
    "                result_dicts.append(result_dict)\n",
    "        else:\n",
    "            for index, result in enumerate(results):\n",
    "                result_events: list[dict[str, Any]] = []\n",
    "                result.process()\n",
    "                for event in result.events:\n",
    "                    try:\n",
    "                        result_events.append(\n",
    "                            event.model_dump(mode=\"json\", fallback=str)\n",
    "                        )\n",
    "                    except BaseException:  # pylint: disable=broad-exception-caught\n",
    "                        pass\n",
    "                result_dict = {\n",
    "                    \"index\": index,\n",
    "                    \"uuid\": str(result.uuid),\n",
    "                    \"events\": result_events,\n",
    "                    \"messages\": result.messages,\n",
    "                    \"summary\": result.summary,\n",
    "                    \"cost\": (\n",
    "                        result.cost.model_dump(mode=\"json\", fallback=str)\n",
    "                        if result.cost\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"context_variables\": (\n",
    "                        result.context_variables.model_dump(mode=\"json\", fallback=str)\n",
    "                        if result.context_variables\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"last_speaker\": result.last_speaker,\n",
    "                }\n",
    "                result_dicts.append(result_dict)\n",
    "\n",
    "        stop_logging()\n",
    "    store_results(result_dicts)\n",
    "    return result_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2493080",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": false,
   "hide_notebook_metadata": true,
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
